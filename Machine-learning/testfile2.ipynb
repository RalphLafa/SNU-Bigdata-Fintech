{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import StandardScaler  # 표준화 패키지 라이브러리 \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost classifier\n",
    "사이킷런 래퍼 XGBoost 모듈 파라미터 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_set, y_set, test_size=0.2, random_state=156)\n",
    "X_val_xgb, X_test_xgb, y_val_xgb, y_test_xgb = train_test_split(X_test_xgb, y_test_xgb, test_size=0.5, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 래퍼와 동일한 하이퍼 파라미터 수치\n",
    "# 트리 100개만 생성\n",
    "xgb_wrapper = XGBClassifier(n_estimators= 100, learning_rate = 0.1, max_depth = 3)\n",
    "#xgb_wrapper = XGBClassifier(n_estimators= 100, learning_rate = 0.1, max_depth = 3,objective= \"multi:softmax\", num_classes = 2) \n",
    "\n",
    "evals = [(X_val_xgb, y_val_xgb)]\n",
    "xgb_wrapper.fit(X_train_xgb, y_train_xgb, early_stopping_rounds= 50, eval_metric='logloss', eval_set = evals)\n",
    "\n",
    "xgb_preds = xgb_wrapper.predict(X_test_xgb)\n",
    "xgb_pred_probs = xgb_wrapper.predict_proba(X_test_xgb)[:,1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_auc_score \\\n",
    "from sklearn.metrics import f1_score \\\n",
    "from sklearn.metrics import precision_recall_curve \\\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test_xgb, xgb_preds)\n",
    "accuracy = accuracy_score(y_test_xgb, xgb_preds)\n",
    "precision = precision_score(y_test_xgb, xgb_preds)\n",
    "recall = recall_score(y_test_xgb, xgb_preds)\n",
    "f1 = f1_score(y_test_xgb, xgb_preds)\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test_xgb, xgb_pred_probs)\n",
    "print('오차 행렬')\n",
    "print(confusion)\n",
    "# ROc-AUC\n",
    "print(\"accuracy : {:.4f}, precision : {:.4f}, recall : {:.4f},\\\n",
    "    f1-score : {:.4f}, AUC : {:.4f}\".format(accuracy,precision,recall,f1,roc_auc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter 설명 - XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Parameters\n",
    "▶ booster [default = 'gbtree'] \\\n",
    "        gbtree : 트리 기반 모델\\\n",
    "        gblinear : 선형 모델\\\n",
    "▶ silent [default = 0]\\\n",
    "        0 : 동작 메세지 프린트 함\\\n",
    "        1 : 동작 메세지 프린트 안함 \\\n",
    "▶ nthread [default = 전체 다 사용]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booster Parameters ( 모델의 조건 설정 )\n",
    "▶ n_estimators [default = 100] : 나무의 개수 (=num_boost_round [default = 10] : 파이썬 래퍼에서 적용)\n",
    "\n",
    "▶ early_stopping_rounds \n",
    "        최대한 몇 개의 트리를 완성해볼 것인지 \n",
    "        valid loss에 더이상 진전이 없으면 멈춤\n",
    "        과적합을 방지할 수 있음, n_estimators 가 높을때 주로 사용.\n",
    "\n",
    " \n",
    "\n",
    "▶ learning_rate [default = 0.1] (=eta [default = 0.3] : 파이썬 래퍼에서 적용)\n",
    "        학습 단계별로 가중치를 얼만큼 사용할지 결정/ 이전의 결과를 얼마나 반영할건지\n",
    "        낮은 eta -> 낮은 가중치 -> 다음 단계의 결과물 적게 반영 -> 보수적\n",
    "        일반적으로 0.01 ~ 0.2\n",
    "        높은 값으로 다른 파라미터 조절하여 결정한 후, 낮춰서 최적의 파라미 결정\n",
    "        * gradient boost에서는 기울기의 의미, 작으면 꼼꼼히 내려가고 크면 급하게 내려감\n",
    "\n",
    "▶ min_child_weight [default = 1]\n",
    "        child 에서 필요한 모든 관측치에 대한 가중치의 최소 합\n",
    "        이 값보다 샘플 수가 작으면 leaf node가 되는 것\n",
    "        너무 크면 under-fitting 될 수 있음\n",
    "        CV로 조절해야함\n",
    "\n",
    " \n",
    "\n",
    "▶ max_depth [default = 6]\n",
    "        트리의 최대 깊이\n",
    "        일반적으로 3 ~ 10  \n",
    "        CV로 조절해야함\n",
    "\n",
    "\n",
    "\n",
    "▶ gamma [default = 0]\n",
    "        트리에서 추가적으로 가지를 나눌지를 결정할 최소 손실 감소 값\\\n",
    "        값이 클수록 과적합 감소 효과\n",
    "\n",
    " \n",
    "\n",
    "▶ subsample [default = 1] (=sub_sample : 파이썬 래퍼에서 적용)\n",
    "        각 트리마다 데이터 샘플링 비율\\\n",
    "        over-fitting 방지\n",
    "        일반적으로 0.5 ~ 1\n",
    "\n",
    "\n",
    "▶ colsample_bytree [default = 1]\n",
    "        각 트리마다 feature 샘플링 비율\\\n",
    "        일반적으로 0.5 ~ 1\n",
    "\n",
    "▶ reg_lambda [default = 1] (=lambda : 파이썬 래퍼에서 적용)\n",
    "        L2 regularization(ex. 릿지) 가중치\\\n",
    "        클수록 보수적\n",
    "\n",
    "▶ reg_alpha [default = 0] (=alpha : 파이썬 래퍼에서 적용)\n",
    "        L1 regularization(ex. 라쏘) 가중치\\\n",
    "        클수록 보수적\n",
    "        특성이 매우 많은때 사용해볼만 함\n",
    "\n",
    " \n",
    "\n",
    "▶ scale_pos_weight [default = 1]\n",
    "        데이터가 불균형할때 사용, 0보다 큰 값\\\n",
    "        보통 값을 음성 데이터 수/ 양성 데이터 수 값으로 함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Task Parameters ( 모델의 목표 및 계산 방법 설정 )\n",
    "\n",
    "▶ objective [default = reg:linear] (목적 함수)\n",
    "- binary:logistic :이진 분류를 위한 로지스틱 회귀, 클래스가 아닌 예측된 확률 반환\n",
    "- multi:softmax : softmax를 사용한 다중 클래스 분류, 확률이 아닌 예측된 클래스 반환\n",
    "- multi:softprob : softmax와 같지만 각 클래스에 대한 예상 확률 반환 \\\n",
    "▶ eval_metric [목적 함수에 따라 디폴트 값이 다름(회귀-rmse / 분류-error)]\n",
    "- rmse : root mean square error\n",
    "- mae : mean absolute error\n",
    "- logloss : negative log-likelihood\n",
    "- error : binary classificaion error rate (임계값 0.5)\n",
    "- merror : multiclass classification error rate\n",
    "- mlogloss : multiclass logloss\n",
    "- auc : area under the curve\\\n",
    "▶ seed [default = 0]\n",
    "        시드값 고정 (나중에 재현할때 같은 값을 출력하기 위해)\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_set, y_set, test_size=0.2, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, random_state=0, max_depth = 3)\n",
    "model.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = model.predict(X_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test_rf, y_pred_rf)\n",
    "tp = confusion[1,1] # true positive\n",
    "tn = confusion[0,0] # true negative\n",
    "fp = confusion[0,1] # false positive\n",
    "fn = confusion[1,0] # false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_rf = tp / (tp + fp) # 정밀도: 모델이 positive라 분류한 것중 실제 값이 positive인 비율\n",
    "recall_rf = tp / (tp+ fn) # 재현도: 실제 값이 positive인 것중 모델이 positive라 분류한 비율\n",
    "f1_score_rf = tp / (tp + ((fn + fp)/2)) #precision과 recall의 조화평균\n",
    "accuracy_rf = (tp + tn) / (tp+fn+fp+tn) # 전체 중 모델이 정확하게 분류한 비율\n",
    "print(\"Precision:\", precision_rf,\"\\nRecall:\\t\", recall_rf,\"\\nf1_score:\", f1_score_rf,\"\\nAccuracy:\",accuracy_rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators : 모델에서 사용할 트리 갯수(학습시 생성할 트리 갯수)\n",
    "- criterion : 분할 품질을 측정하는 기능 (default : gini)\n",
    "- max_depth : 트리의 최대 깊이\n",
    "- min_samples_split : 내부 노드를 분할하는데 필요한 최소 샘플 수 (default : 2)\n",
    "- min_samples_leaf : 리프 노드에 있어야 할 최소 샘플 수 (default : 1)\n",
    "- min_weight_fraction_leaf : min_sample_leaf와 같지만 가중치가 부여된 샘플 수에서의 비율\n",
    "- max_features : 각 노드에서 분할에 사용할 특징의 최대 수\n",
    "- max_leaf_nodes : 리프 노드의 최대수\n",
    "- min_impurity_decrease : 최소 불순도\n",
    "- min_impurity_split : 나무 성장을 멈추기 위한 임계치\n",
    "- bootstrap : 부트스트랩(중복허용 샘플링) 사용 여부\n",
    "- oob_score : 일반화 정확도를 줄이기 위해 밖의 샘플 사용 여부\n",
    "- n_jobs :적합성과 예측성을 위해 병렬로 실행할 작업 수\n",
    "- random_state : 난수 seed 설정\n",
    "- verbose : 실행 과정 출력 여부\n",
    "- warm_start : 이전 호출의 솔루션을 재사용하여 합계에 더 많은 견적가를 추가\n",
    "- class_weight : 클래스 가중치"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_set, y_set, test_size=0.2, random_state= 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_sate= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit = LogisticRegression(fit_intercept= True, penalty = 'none', solver = 'newton-cg')\n",
    "lasso = LogisticRegression(fit_intercept= True,  penalty='l1', solver='liblinear', C = 1.0) # LASSO regression\n",
    "\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define thresholds with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lasso = pd.DataFrame(lasso.predict_proba(X_val)[:, 1],columns =['pred_prob'])\n",
    "result_lasso.pred_prob.plot(kind='hist',bins=50, xlim=([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, result_lasso.pred_prob)\n",
    "roc_result_lasso = pd.DataFrame([fpr,tpr,thresholds], index=['fpr','tpr','thresholds']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_result_lasso['best'] = (1-roc_result_lasso['fpr'])+(roc_result_lasso['tpr']) # (1-fpr) + tpr => 제대로 분류되는 것의 비율을 maximize하는 것\n",
    "roc_result_lasso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold_lasso =roc_result_lasso.thresholds[roc_result_lasso.best.idxmax()]\n",
    "\n",
    "print(\"optimal_threshold:\",optimal_threshold_lasso)\n",
    "print(\"value of purpose function on the optimal_threshold:\",roc_result_lasso[roc_result_lasso['thresholds']==optimal_threshold_lasso]['best'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lasso['test_pred_prob'] = lasso.predict_proba(X_test)[:, 1]\n",
    "\n",
    "result_lasso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the histogram\n",
    "plt.hist(result_lasso['test_pred_prob'], bins=10)\n",
    "\n",
    "# add a vertical line at the cut-off value\n",
    "plt.axvline(x=optimal_threshold_lasso, color='red', linestyle='--')\n",
    "\n",
    "# set the x and y axis labels\n",
    "plt.xlabel('probability')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.xlim([0, 1])      # X축의 범위: [xmin, xmax]\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lasso['lasso_binary'] = np.where(result_lasso.test_pred_prob >= optimal_threshold_lasso, 1, 0)\n",
    "confusion = confusion_matrix(y_test, result_lasso.lasso_binary)\n",
    "tp = confusion[1,1] # true positive\n",
    "tn = confusion[0,0] # true negative\n",
    "fp = confusion[0,1] # false positive\n",
    "fn = confusion[1,0] # false negative\n",
    "sns.heatmap(confusion, annot = True, cmap = 'Blues', fmt='g')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()\n",
    "precision_lasso = tp / (tp + fp) # 정밀도: 모델이 positive라 분류한 것중 실제 값이 positive인 비율\n",
    "recall_lasso = tp / (tp+ fn) # 재현도: 실제 값이 positive인 것중 모델이 positive라 분류한 비율\n",
    "f1_score_lasso = tp / (tp + ((fn + fp)/2)) #precision과 recall의 조화평균\n",
    "accuracy_lasso = (tp + tn) / (tp+fn+fp+tn) # 전체 중 모델이 정확하게 분류한 비율\n",
    "print(\"Precision:\", precision_lasso,\"\\nRecall:\\t\", recall_lasso,\"\\nf1_score:\", f1_score_lasso,\"\\nAccuracy:\",accuracy_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_lasso = auc(fpr, tpr)\n",
    "print('roc_auc:', roc_auc_lasso)\n",
    "\n",
    "#lpm과 동일한 방법으로 AUROC 그리기\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area= %0.2f)' % roc_auc_lasso)\n",
    "\n",
    "##그래프에 직선 추가하기\n",
    "plt.plot([0,1],[0,1],color='darkorange', linestyle='--')\n",
    "\n",
    "#x축과 y축 구간 설정하기\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1.05])\n",
    "\n",
    "#축 이름 및 그래프 타이틀, 레전드 추가하기\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve :RandomForest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
